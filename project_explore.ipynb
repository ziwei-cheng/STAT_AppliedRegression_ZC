{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sunrise-guard",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependencies ‘processx’, ‘xfun’, ‘blob’, ‘lifecycle’, ‘tidyselect’, ‘vctrs’, ‘glue’, ‘isoband’, ‘callr’, ‘knitr’, ‘ellipsis’, ‘dbplyr’, ‘dplyr’, ‘ggplot2’, ‘haven’, ‘hms’, ‘modelr’, ‘pillar’, ‘purrr’, ‘readr’, ‘reprex’, ‘rlang’, ‘rvest’, ‘tibble’, ‘tidyr’, ‘xml2’\n",
      "\n",
      "Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘processx’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘xfun’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘glue’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘isoband’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘rlang’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘xml2’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘lifecycle’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘callr’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘knitr’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘ellipsis’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘purrr’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘vctrs’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘reprex’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘blob’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘tidyselect’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘hms’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘pillar’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘tibble’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘dplyr’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘ggplot2’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘readr’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘rvest’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘dbplyr’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘haven’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘tidyr’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘modelr’ had non-zero exit status”Warning message in install.packages(\"tidyverse\"):\n",
      "“installation of package ‘tidyverse’ had non-zero exit status”Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"tidyverse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "italian-segment",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(ggplot2): there is no package called ‘ggplot2’\n",
     "output_type": "error",
     "traceback": [
      "Error in library(ggplot2): there is no package called ‘ggplot2’\nTraceback:\n",
      "1. library(ggplot2)"
     ]
    }
   ],
   "source": [
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "conservative-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d<-read.delim('mdd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "arranged-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_b<-read.csv('bipolar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reserved-withdrawal",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in as.tibble(data_d): could not find function \"as.tibble\"\n",
     "output_type": "error",
     "traceback": [
      "Error in as.tibble(data_d): could not find function \"as.tibble\"\nTraceback:\n",
      "1. print(as.tibble(data_d))"
     ]
    }
   ],
   "source": [
    "#A1 indicating the effect allele\n",
    "#A2 indicating the non-effect allele\n",
    "#logistic or continuous regression effect\n",
    "#p-value associated with this effect\n",
    "print(as.tibble(data_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "center-bidding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 108,834 x 10\n",
      "   SNP          CHR      BP A1    A2       OR     SE    PVAL  INFO   NGT\n",
      "   <fct>      <int>   <int> <fct> <fct> <dbl>  <dbl>   <dbl> <dbl> <int>\n",
      " 1 rs10907175     1 1120590 A     C     0.964 0.0399 0.352   0.982     0\n",
      " 2 rs2887286      1 1145994 C     T     1.03  0.0312 0.390   1.01      0\n",
      " 3 rs6685064      1 1201155 C     T     1.00  0.0478 0.944   0.984     0\n",
      " 4 rs6603791      1 1490804 A     G     1.01  0.0249 0.596   1.00      0\n",
      " 5 rs3737628      1 1712792 C     T     0.975 0.0232 0.281   1.00      0\n",
      " 6 rs3855951      1 1794162 C     T     0.990 0.0528 0.853   0.992     0\n",
      " 7 rs16824526     1 1807989 A     C     1.09  0.0309 0.00717 1.01      0\n",
      " 8 rs908742       1 2023116 A     G     1.04  0.0257 0.0944  0.919     0\n",
      " 9 rs3753242      1 2059541 C     T     0.912 0.0495 0.0615  0.924     0\n",
      "10 rs2257182      1 2072426 C     T     0.968 0.0238 0.169   1.00      0\n",
      "# … with 108,824 more rows\n"
     ]
    }
   ],
   "source": [
    "print(as.tibble(data_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "planned-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "munge <- function(files,hm3,trait.names=NULL,N,info.filter = .9,maf.filter=0.01){\n",
    "  \n",
    "  length <- length(files)\n",
    "  filenames <- as.vector(files)\n",
    "\n",
    "  log2<-paste(trait.names,collapse=\"_\")\n",
    "  \n",
    " if(object.size(log2) > 200){\n",
    "    log2<-substr(log2,1,100)\n",
    "  }\n",
    "\n",
    "  log.file <- file(paste0(log2, \"_munge.log\"),open=\"wt\")\n",
    "  \n",
    "  begin.time <- Sys.time()\n",
    "  \n",
    "  cat(print(paste0(\"The munging of \", length(trait.names), \" summary statistics started at \",begin.time), sep = \"\"),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "  \n",
    "  cat(print(paste(\"Reading summary statistics for\", paste(files,collapse=\" \"), \". Please note that this step usually takes a few minutes due to the size of summary statistic files.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "  \n",
    "  ##note that fread is not used here due to formatting differences across summary statistic files\n",
    "  files = lapply(files, read.table,header=T, quote=\"\\\"\",fill=T,na.string=c(\".\",NA,\"NA\",\"\"))\n",
    "  cat(print(\"Reading in reference file\"),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "  ref <- fread(hm3,header=T,data.table=F)\n",
    "  cat(print(\"All files loaded into R!\"),file=log.file,sep=\"\\n\",append=TRUE)\n",
    " \n",
    "  for(i in 1:length){\n",
    "    \n",
    "    cat(paste(\"     \"),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    cat(paste(\"     \"),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    \n",
    "    cat(print(paste(\"Munging file:\", filenames[i])),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    hold_names <- toupper(names(files[[i]]))\n",
    "\n",
    "    names1<-hold_names\n",
    "    if(\"SNP\" %in% hold_names) cat(print(paste(\"Interpreting the SNP column as the SNP column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    hold_names[hold_names %in% c(\"SNP\",\"SNPID\",\"RSID\",\"RS_NUMBER\",\"RS_NUMBERS\", \"MARKERNAME\", \"ID\",\"PREDICTOR\")] <- \"SNP\"\n",
    "    if(length(base::setdiff(names1,hold_names)) > 0) cat(print(paste(\"Interpreting the\", setdiff(names1, hold_names), \"column as the SNP column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "   \n",
    "    names1<-hold_names\n",
    "    if(\"A1\" %in% hold_names) cat(print(paste(\"Interpreting the A1 column as the A1 column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    hold_names[hold_names %in%c(\"A1\", \"ALLELE1\",\"EFFECT_ALLELE\",\"INC_ALLELE\",\"REFERENCE_ALLELE\",\"EA\",\"REF\")] <- \"A1\"\n",
    "    if(length(base::setdiff(names1,hold_names)) > 0) cat(print(paste(\"Interpreting the\", setdiff(names1, hold_names), \"column as the A1 column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    \n",
    "    names1<-hold_names\n",
    "    if(\"A2\" %in% hold_names) cat(print(paste(\"Interpreting the A2 column as the A2 column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "     hold_names[hold_names %in%c(\"A2\",\"ALLELE2\",\"ALLELE0\",\"OTHER_ALLELE\",\"REF\",\"NON_EFFECT_ALLELE\",\"DEC_ALLELE\",\"OA\",\"NEA\", \"ALT\")]  <- \"A2\"\n",
    "    if(length(base::setdiff(names1,hold_names)) > 0) cat(print(paste(\"Interpreting the\", setdiff(names1, hold_names), \"column as the A2 column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    \n",
    "    names1<-hold_names\n",
    "    if(\"effect\" %in% hold_names) cat(print(paste(\"Interpreting the effect column as the effect column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    hold_names[hold_names %in%c(\"OR\",\"B\",\"BETA\",\"LOG_ODDS\",\"EFFECTS\",\"EFFECT\",\"SIGNED_SUMSTAT\", \"Z\",\"ZSCORE\",\"EST\",\"ZSTAT\",\"ZSTATISTIC\", \"BETA1\")] <- \"effect\"\n",
    "    if(length(base::setdiff(names1,hold_names)) > 0) cat(print(paste(\"Interpreting the\", setdiff(names1, hold_names), \"column as the effect column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    \n",
    "    names1<-hold_names\n",
    "    if(\"INFO\" %in% hold_names) cat(print(paste(\"Interpreting the INFO column as the INFO column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    hold_names[hold_names %in%c(\"INFO\")] <- \"INFO\"\n",
    "    if(length(base::setdiff(names1,hold_names)) > 0) cat(print(paste(\"Interpreting the\", setdiff(names1, hold_names), \"column as the INFO column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    \n",
    "    names1<-hold_names\n",
    "    if(\"P\" %in% hold_names) cat(print(paste(\"Interpreting the P column as the P column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    hold_names[hold_names %in%c(\"P\",\"PVALUE\",\"PVAL\",\"P_VALUE\",\"P-VALUE\",\"P.VALUE\",\"P_VAL\",\"GC_PVALUE\",\"WALD_P\")] <- \"P\"\n",
    "    if(length(base::setdiff(names1,hold_names)) > 0) cat(print(paste(\"Interpreting the\", setdiff(names1, hold_names), \"column as the P column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    \n",
    "    names1<-hold_names\n",
    "    if(\"N\" %in% hold_names) cat(print(paste(\"Interpreting the N column as the N (sample size) column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    hold_names[hold_names %in%c(\"N\",\"WEIGHT\",\"NCOMPLETESAMPLES\", \"TOTALSAMPLESIZE\", \"TOTALN\", \"TOTAL_N\",\"N_COMPLETE_SAMPLES\" )] <- \"N\"\n",
    "    if(length(base::setdiff(names1,hold_names)) > 0) cat(print(paste(\"Interpreting the \", setdiff(names1, hold_names), \" column as the N (sample size) column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    \n",
    "    names1<-hold_names\n",
    "    if(\"N_CAS\" %in% hold_names) cat(print(paste(\"Interpreting the N_CAS column as the N_CAS (sample size for cases) column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    hold_names[hold_names %in%c(\"NCASE\",\"N_CASE\",\"N_CASES\",\"N_CAS\", \"NCAS\", \"NCA\")] <- \"N_CAS\"\n",
    "    if(length(base::setdiff(names1,hold_names)) > 0) cat(print(paste(\"Interpreting the \", setdiff(names1, hold_names), \" column as the N_CAS (sample size for cases) column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    \n",
    "    names1<-hold_names\n",
    "    if(\"N_CON\" %in% hold_names) cat(print(paste(\"Interpreting the N_CON column as the N_CON (sample size for controls) column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    hold_names[hold_names %in%c(\"NCONTROL\",\"N_CONTROL\",\"N_CONTROLS\",\"N_CON\",\"CONTROLS_N\", \"NCON\", \"NCO\")] <- \"N_CON\"\n",
    "    if(length(base::setdiff(names1,hold_names)) > 0) cat(print(paste(\"Interpreting the \", setdiff(names1, hold_names), \" column as the N_CON (sample size for controls) column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    " \n",
    "    # Print a message for misisng P value, rs, effect or allele columns\n",
    "    if(sum(hold_names %in% \"P\") == 0) cat(print(paste0('Cannot find P-value column, try renaming it to P in the summary statistics file for:',filenames[i])),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    if(sum(hold_names %in% \"A1\") == 0) cat(print(paste0('Cannot find effect allele column, try renaming it to A1 in the summary statistics file for:',filenames[i])),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    if(sum(hold_names %in% \"A2\") == 0) cat(print(paste0('Cannot find other allele column, try renaming it to A2 in the summary statistics file for:',filenames[i])),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    if(sum(hold_names %in% \"effect\") == 0) cat(print(paste0('Cannot find beta or effect column, try renaming it to effect in the summary statistics file for:',filenames[i])),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    if(sum(hold_names %in% \"SNP\") == 0) cat(print(paste0('Cannot find rs-id column, try renaming it to SNP in the summary statistics file for:',filenames[i])),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    \n",
    "    # Print a warning message when multiple columns interprets as P value, rs, effect or allele columns\n",
    "    if(sum(hold_names %in% \"P\") > 1) cat(print(paste0('Multiple columns are being interpreted as the P-value column. Try renaming the column you dont want interpreted as P to P2 for:',filenames[i])),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    if(sum(hold_names %in% \"A1\") > 1) cat(print(paste0('Multiple columns are being interpreted as the effect allele column. Try renaming the column you dont want interpreted as effect allele column to A1_2 for:',filenames[i])),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    if(sum(hold_names %in% \"A2\") > 1) cat(print(paste0('Multiple columns are being interpreted as the other allele column. Try renaming the column you dont want interpreted as the other allele column to A2_2 for:',filenames[i])),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    if(sum(hold_names %in% \"effect\") > 1) cat(print(paste0('Multiple columns are being interpreted as the beta or effect column. Try renaming the column you dont want interpreted as the beta or effect column to effect2 for:',filenames[i])),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    if(sum(hold_names %in% \"SNP\") > 1) cat(print(paste0('Multiple columns are being interpreted as the rs-id column. Try renaming the column you dont want interpreted as rs-id to SNP2 for:',filenames[i])),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    \n",
    "    # Throw warnings for misisng P valuue, rs, effect or allele columns\n",
    "    if(sum(hold_names %in% \"P\") == 0) warning(paste0('Cannot find P-value column, try renaming it P in the summary statistics file for:',filenames[i]))\n",
    "    if(sum(hold_names %in% \"A1\") == 0) warning(paste0('Cannot find effect allele column, try renaming it A1 in the summary statistics file for:',filenames[i]))\n",
    "    if(sum(hold_names %in% \"A2\") == 0) warning(paste0('Cannot find other allele column, try renaming it A2 in the summary statistics file for:',filenames[i]))\n",
    "    if(sum(hold_names %in% \"effect\") == 0) warning(paste0('Cannot find beta or effect column, try renaming it effect in the summary statistics file for:',filenames[i]))\n",
    "    if(sum(hold_names %in% \"SNP\") == 0) warning(paste0('Cannot rs-id column, try renaming it SNP in the summary statistics file for:',filenames[i]))\n",
    "    \n",
    "    ##rename common MAF labels\n",
    "    names1<-hold_names\n",
    "    if(\"MAF\" %in% hold_names) cat(print(paste(\"Interpreting the MAF column as the MAF (minor allele frequency) column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    hold_names[hold_names %in% c(\"MAF\", \"CEUAF\", \"FREQ1\", \"EAF\", \"FREQ1.HAPMAP\", \"FREQALLELE1HAPMAPCEU\", \"FREQ.ALLELE1.HAPMAPCEU\", \"EFFECT_ALLELE_FREQ\", \"FREQ.A1\")] <- \"MAF\"\n",
    "    if(length(setdiff(names1,hold_names)) > 0) cat(print(paste(\"Interpreting the \", setdiff(names1, hold_names), \" column as the MAF (minor allele frequency) column.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    \n",
    "    #Replace the origonal names\n",
    "    names(files[[i]]) <- hold_names\n",
    "\n",
    "    if(\"MAF\" %in% colnames(files[[i]])) {\n",
    "      ##make sure MAF is actually MAF (i.e., max value is .5 or less)\n",
    "      files[[i]]$MAF<-ifelse(files[[i]]$MAF <= .5, files[[i]]$MAF, (1-files[[i]]$MAF))\n",
    "    }\n",
    "    \n",
    "    # Compute N is N cases and N control is reported:\n",
    "    if(\"N_CAS\" %in% colnames(files[[i]])) {\n",
    "      files[[i]]$N <- files[[i]]$N_CAS + files[[i]]$N_CON\n",
    "      cat(print(paste(\"As the file includes both N_CAS and N_CON columns, the summation of these two columns will be used as the total sample size\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    }\n",
    "    \n",
    "    ##make sure all alleles are upper case for matching to reference file\n",
    "    files[[i]]$A1 <- factor(toupper(files[[i]]$A1), c(\"A\", \"C\", \"G\", \"T\"))\n",
    "    files[[i]]$A2 <- factor(toupper(files[[i]]$A2), c(\"A\", \"C\", \"G\", \"T\"))\n",
    "    \n",
    "    ##merge with ref file\n",
    "    cat(print(paste(\"Merging file:\", filenames[i], \"with the reference file:\", hm3)),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    b<-nrow(files[[i]])\n",
    "    cat(print(paste(b, \"rows present in the full\", filenames[i], \"summary statistics file.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    files[[i]] <- merge(ref,files[[i]],by=\"SNP\",all.x=F,all.y=F)\n",
    "    cat(print(paste((b-nrow(files[[i]])), \"rows were removed from the\", filenames[i], \"summary statistics file as the rs-ids for these rows were not present in the reference file.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    \n",
    "    ##remove any rows with missing p-values\n",
    "    b<-nrow(files[[i]])\n",
    "    if(\"P\" %in% colnames(files[[i]])) {\n",
    "      files[[i]]<-subset(files[[i]], !(is.na(files[[i]]$P)))\n",
    "    }\n",
    "    if(b-nrow(files[[i]]) > 0) cat(print(paste(b-nrow(files[[i]]), \"rows were removed from the\", filenames[i], \"summary statistics file due to missing values in the P-value column\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    \n",
    "    ##remove any rows with missing effects\n",
    "    b<-nrow(files[[i]])\n",
    "    if(\"effect\" %in% colnames(files[[i]])) {\n",
    "      files[[i]]<-subset(files[[i]], !(is.na(files[[i]]$effect)))\n",
    "    }\n",
    "    if(b-nrow(files[[i]]) > 0) cat(print(paste(b-nrow(files[[i]]), \"rows were removed from the\", filenames[i], \"summary statistics file due to missing values in the effect column\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    \n",
    "    ##determine whether it is OR or logistic/continuous effect based on median effect size \n",
    "    a1<-files[[i]]$effect[[1]]\n",
    "    files[[i]]$effect<-ifelse(rep(round(median(files[[i]]$effect,na.rm=T)) == 1,nrow(files[[i]])), log(files[[i]]$effect),files[[i]]$effect)\n",
    "    a2<-files[[i]]$effect[[1]]\n",
    "    if(a1 != a2) cat(print(paste(\"The effect column was determined to be coded as an odds ratio (OR) for the\", filenames[i], \"summary statistics file. Please ensure this is correct.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    \n",
    "    # Flip effect to match ordering in ref file\n",
    "    files[[i]]$effect<-ifelse(files[[i]]$A1.x != (files[[i]]$A1.y) & files[[i]]$A1.x == (files[[i]]$A2.y),files[[i]]$effect*-1,files[[i]]$effect)\n",
    "    \n",
    "    ##remove SNPs that don't match A1 OR A2 in reference file.\n",
    "    b<-nrow(files[[i]])\n",
    "    files[[i]]<-subset(files[[i]], !(files[[i]]$A1.x != (files[[i]]$A1.y)  & files[[i]]$A1.x != (files[[i]]$A2.y)))\n",
    "    if(b-nrow(files[[i]]) > 0) cat(print(paste(b-nrow(files[[i]]), \"row(s) were removed from the\", filenames[i], \"summary statistics file due to the effect allele (A1) column not matching A1 or A2 in the reference file.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "  \n",
    "    b<-nrow(files[[i]])\n",
    "    files[[i]]<-subset(files[[i]], !(files[[i]]$A2.x != (files[[i]]$A2.y)  & files[[i]]$A2.x !=  (files[[i]]$A1.y)))\n",
    "    if(b-nrow(files[[i]]) > 0) cat(print(paste(b-nrow(files[[i]]), \"row(s) were removed from the\", filenames[i], \"summary statistics file due to the other allele (A2) column not matching A1 or A2 in the reference file.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    \n",
    "    ####VALIDITY CHECKS#####\n",
    "    \n",
    "    #Check that p-value column does not contain an excess of 1s/0s\n",
    "    if((sum(files[[i]]$P > 1) + sum(files[[i]]$P < 0)) > 100){\n",
    "      cat(print(\"In excess of 100 SNPs have P val above 1 or below 0. The P column may be mislabled!\"),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    }\n",
    "   \n",
    "    #Compute Z score\n",
    "    files[[i]]$Z <- sign(files[[i]]$effect) * sqrt(qchisq(files[[i]]$P,1,lower=F))\n",
    "    \n",
    "    ##filter on INFO column at designated threshold provided for the info.filter argument (default = 0.9)\n",
    "    if(\"INFO\" %in% colnames(files[[i]])) {\n",
    "      b<-nrow(files[[i]])\n",
    "      files[[i]] <- files[[i]][files[[i]]$INFO >= info.filter,]\n",
    "      cat(print(paste(b-nrow(files[[i]]), \"rows were removed from the\", filenames[i], \"summary statistics file due to INFO values below the designated threshold of\", info.filter)),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    }else{cat(print(\"No INFO column, cannot filter on INFO, which may influence results\"),file=log.file,sep=\"\\n\",append=TRUE)}\n",
    "    \n",
    "    ##filter on MAF filter at designated threshold provided for the maf.filter argument (default = 0.01)\n",
    "    if(\"MAF\" %in% colnames(files[[i]])) {\n",
    "      files[[i]]$MAF<-as.numeric(as.character(files[[i]]$MAF))\n",
    "      b<-nrow(files[[i]])\n",
    "      files[[i]] <- files[[i]][files[[i]]$MAF >= maf.filter,]\n",
    "      files[[i]]<-subset(files[[i]], !(is.na(files[[i]]$MAF)))\n",
    "      cat(print(paste(b-nrow(files[[i]]), \"rows were removed from the\", filenames[i], \"summary statistics file due to missing MAF information or MAFs below the designated threshold of\", maf.filter)),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    }else{cat(print(\"No MAF column, cannot filter on MAF, which may influence results\"),file=log.file,sep=\"\\n\",append=TRUE)}\n",
    "\n",
    "    if(\"N\" %in% colnames(files[[i]])) {\n",
    "      output <- cbind.data.frame(files[[i]]$SNP,files[[i]]$N,files[[i]]$Z,files[[i]]$A1.x,files[[i]]$A2.x)\n",
    "    }else{output <- cbind.data.frame(files[[i]]$SNP,N[i],files[[i]]$Z,files[[i]]$A1.x,files[[i]]$A2.x) }\n",
    "    \n",
    "    if(!(\"N\" %in% names(files[[i]])) & (exists(\"N\") == FALSE)) cat(warning(paste0('Cannot find sample size column for',filenames[i], \" and a sample size was not provided for the N argument. Please either provide a total sample size to the N argument or try changing the name of the sample size column to N.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "\n",
    "    colnames(output) <- c(\"SNP\",\"N\",\"Z\",\"A1\",\"A2\")\n",
    "    cat(print(paste(nrow(output), \"SNPs are left in the summary statistics file\", filenames[i], \"after QC.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    \n",
    "    #remove spaces in trait.names file to avoid errors with fread functionality used for s_ldsc\n",
    "    trait.names[i]<-str_replace_all(trait.names[i], fixed(\" \"), \"\") \n",
    "    \n",
    "    write.table(x = output,file = paste0(trait.names[i],\".sumstats\"),sep=\"\\t\", quote = FALSE, row.names = F)\n",
    "    #gzip(paste0(trait.names[i],\".sumstats\"))\n",
    "    cat(print(paste(\"I am done munging file:\", filenames[i])),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    cat(print(paste(\"The file is saved as\", paste0(trait.names[i],\".sumstats.gz\"), \"in the current working directory.\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "  }\n",
    "  \n",
    "  end.time <- Sys.time()\n",
    "  \n",
    "  total.time <- difftime(time1=end.time,time2=begin.time,units=\"sec\")\n",
    "  mins <- floor(floor(total.time)/60)\n",
    "  secs <- total.time-mins*60\n",
    "  \n",
    "  cat(paste(\"     \"),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "  cat(print(paste0(\"Munging was completed at \",end.time), sep = \"\"),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "  \n",
    "  cat(print(paste0(\"The munging of all files took \",mins,\" minutes and \",secs,\" seconds\"), sep = \"\"),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "  cat(print(paste(\"Please check the log file\", paste0(log2, \"_munge.log\"), \"to ensure that all columns were interpreted correctly and no warnings were issued for any of the summary statistics files\")),file=log.file,sep=\"\\n\",append=TRUE)\n",
    "    \n",
    "  flush(log.file)\n",
    "  close(log.file)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "vital-substance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"The munging of 2 summary statistics started at 2021-04-11 12:21:08\"\n",
      "[1] \"Reading summary statistics for mdd_withRS.txt bipolar.txt . Please note that this step usually takes a few minutes due to the size of summary statistic files.\"\n",
      "[1] \"Reading in reference file\"\n",
      "[1] \"All files loaded into R!\"\n",
      "[1] \"Munging file: mdd_withRS.txt\"\n",
      "[1] \"Interpreting the SNP column as the SNP column.\"\n",
      "[1] \"Interpreting the A1 column as the A1 column.\"\n",
      "[1] \"Interpreting the A2 column as the A2 column.\"\n",
      "[1] \"Interpreting the OR column as the effect column.\"\n",
      "[1] \"Interpreting the INFO column as the INFO column.\"\n",
      "[1] \"Interpreting the P column as the P column.\"\n",
      "[1] \"Merging file: mdd_withRS.txt with the reference file: w_hm3.noMHC.snplist\"\n",
      "[1] \"10000 rows present in the full mdd_withRS.txt summary statistics file.\"\n",
      "[1] \"7074 rows were removed from the mdd_withRS.txt summary statistics file as the rs-ids for these rows were not present in the reference file.\"\n",
      "[1] \"The effect column was determined to be coded as an odds ratio (OR) for the mdd_withRS.txt summary statistics file. Please ensure this is correct.\"\n",
      "[1] \"0 rows were removed from the mdd_withRS.txt summary statistics file due to INFO values below the designated threshold of 0.9\"\n",
      "[1] \"No MAF column, cannot filter on MAF, which may influence results\"\n",
      "[1] \"2926 SNPs are left in the summary statistics file mdd_withRS.txt after QC.\"\n",
      "[1] \"I am done munging file: mdd_withRS.txt\"\n",
      "[1] \"The file is saved as mdd.sumstats.gz in the current working directory.\"\n",
      "[1] \"Munging file: bipolar.txt\"\n",
      "[1] \"Interpreting the SNP column as the SNP column.\"\n",
      "[1] \"Interpreting the A1 column as the A1 column.\"\n",
      "[1] \"Interpreting the A2 column as the A2 column.\"\n",
      "[1] \"Interpreting the OR column as the effect column.\"\n",
      "[1] \"Interpreting the INFO column as the INFO column.\"\n",
      "[1] \"Interpreting the PVAL column as the P column.\"\n",
      "[1] \"Merging file: bipolar.txt with the reference file: w_hm3.noMHC.snplist\"\n",
      "[1] \"108834 rows present in the full bipolar.txt summary statistics file.\"\n",
      "[1] \"42758 rows were removed from the bipolar.txt summary statistics file as the rs-ids for these rows were not present in the reference file.\"\n",
      "[1] \"The effect column was determined to be coded as an odds ratio (OR) for the bipolar.txt summary statistics file. Please ensure this is correct.\"\n",
      "[1] \"6 row(s) were removed from the bipolar.txt summary statistics file due to the effect allele (A1) column not matching A1 or A2 in the reference file.\"\n",
      "[1] \"0 rows were removed from the bipolar.txt summary statistics file due to INFO values below the designated threshold of 0.9\"\n",
      "[1] \"No MAF column, cannot filter on MAF, which may influence results\"\n",
      "[1] \"66070 SNPs are left in the summary statistics file bipolar.txt after QC.\"\n",
      "[1] \"I am done munging file: bipolar.txt\"\n",
      "[1] \"The file is saved as bipolar.sumstats.gz in the current working directory.\"\n",
      "[1] \"Munging was completed at 2021-04-11 12:21:10\"\n",
      "[1] \"The munging of all files took 0 minutes and 2.4153368473053 seconds\"\n",
      "[1] \"Please check the log file mdd_bipolar_munge.log to ensure that all columns were interpreted correctly and no warnings were issued for any of the summary statistics files\"\n"
     ]
    }
   ],
   "source": [
    "mdd<-fread(\"mdd\",data.table=FALSE) \n",
    "\n",
    "##pull out the rsIDs##\n",
    "mdd$SNP<-sapply(strsplit(mdd$SNP, \":\"), `[`, 1)\n",
    "\n",
    "##output the result in a .txt file called scz_withRS.txt##\n",
    "write.table(mdd, file = \"mdd_withRS.txt\", sep = \"\\t\", quote = FALSE, row.names = FALSE, col.names=TRUE)\n",
    "\n",
    "##munge the summary statistics files##\n",
    "##note that we include the argument names (e.g., files, hm3) for\n",
    "##completeness in the code below, but that this is not necessary to run the code.\n",
    "munge(files=c(\"mdd_withRS.txt\",\"bipolar.txt\"), hm3 = \"w_hm3.noMHC.snplist\",trait.names=c(\"mdd\", \"bipolar\"),N=c(10000, 108,834), info.filter = 0.9, maf.filter = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "southern-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_d<-read.delim('mdd.sumstats')\n",
    "sum_b<-read.delim('bipolar.sumstats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "digital-dancing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 2,926 x 5\n",
      "   SNP            N     Z A1    A2   \n",
      "   <fct>      <int> <dbl> <fct> <fct>\n",
      " 1 rs1000055  10000  3.06 A     G    \n",
      " 2 rs10001274 10000  2.62 C     T    \n",
      " 3 rs10013659 10000 -2.61 A     G    \n",
      " 4 rs10017241 10000 -2.73 G     A    \n",
      " 5 rs1001823  10000  2.45 C     T    \n",
      " 6 rs1002765  10000 -2.87 A     G    \n",
      " 7 rs10033316 10000  2.45 C     T    \n",
      " 8 rs1003503  10000 -2.50 T     C    \n",
      " 9 rs1004018  10000  2.61 A     G    \n",
      "10 rs1004212  10000  3.39 T     C    \n",
      "# … with 2,916 more rows\n",
      "# A tibble: 66,070 x 5\n",
      "   SNP            N      Z A1    A2   \n",
      "   <fct>      <int>  <dbl> <fct> <fct>\n",
      " 1 rs10000041   108  1.83  G     T    \n",
      " 2 rs10000193   108  2.52  A     G    \n",
      " 3 rs10000226   108  0.458 T     C    \n",
      " 4 rs10000282   108 -1.80  T     C    \n",
      " 5 rs1000040    108 -1.63  G     A    \n",
      " 6 rs10000609   108 -0.886 G     A    \n",
      " 7 rs10000748   108 -1.42  T     C    \n",
      " 8 rs10000807   108 -0.986 A     G    \n",
      " 9 rs10000959   108  1.44  C     T    \n",
      "10 rs10001030   108  0.968 G     A    \n",
      "# … with 66,060 more rows\n"
     ]
    }
   ],
   "source": [
    "print(as.tibble(sum_d))\n",
    "print(as.tibble(sum_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "trying-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldsc <- function(traits, sample.prev, population.prev, ld, wld,\n",
    "                trait.names = NULL, sep_weights = FALSE, chr = 22,\n",
    "                n.blocks = 200, ldsc.log = NULL, stand = FALSE,select=FALSE,chisq.max = NA) {\n",
    "  \n",
    "  LOG <- function(..., print = TRUE) {\n",
    "    msg <- paste0(...)\n",
    "    if (print) print(msg)\n",
    "    cat(msg, file = log.file, sep = \"\\n\", append = TRUE)\n",
    "  }\n",
    "  \n",
    "  time <- proc.time()\n",
    "  \n",
    "  begin.time <- Sys.time()\n",
    "  \n",
    "  if(is.null(ldsc.log)){\n",
    "    logtraits<-gsub(\".*/\",\"\",traits)\n",
    "    log2<-paste(logtraits,collapse=\"_\")\n",
    "    if(object.size(log2) > 200){\n",
    "      log2<-substr(log2,1,100)\n",
    "    }\n",
    "    log.file <- file(paste0(log2, \"_ldsc.log\"),open=\"wt\")\n",
    "  }else{log.file<-file(paste0(ldsc.log, \"_ldsc.log\"),open=\"wt\")}\n",
    "  \n",
    "  LOG(\"Multivariate ld-score regression of \", length(traits), \" traits \",\n",
    "      \"(\", paste(traits, collapse = \" \"), \")\", \" began at: \", begin.time)\n",
    "  \n",
    "  \n",
    "  if(select == \"ODD\" | select == \"EVEN\"){\n",
    "  odd<-seq(1,chr,2)\n",
    "  even<-seq(2,chr,2)\n",
    "  }\n",
    "  \n",
    "  # Dimensions\n",
    "  n.traits <- length(traits)\n",
    "  n.V <- n.traits * (n.traits + 1) / 2\n",
    "  \n",
    "  if(!(is.null(trait.names))){\n",
    "    check_names<-str_detect(trait.names, \"-\")\n",
    "    if(any(check_names))\n",
    "      warning(\"Your trait names specified include mathematical arguments (e.g., + or -) that will be misread by lavaan. Please rename the traits using the trait.names argument.\")\n",
    "  }\n",
    "  \n",
    "  if(length(traits)==1)\n",
    "    warning(\"Our version of ldsc requires 2 or more traits. Please include an additional trait.\")\n",
    "  \n",
    "  \n",
    "  # Storage:\n",
    "  cov <- matrix(NA,nrow=n.traits,ncol=n.traits)\n",
    "  V.hold <- matrix(NA,nrow=n.blocks,ncol=n.V)\n",
    "  N.vec <- matrix(NA,nrow=1,ncol=n.V)\n",
    "  Liab.S <- rep(1, n.traits)\n",
    "  I <- matrix(NA,nrow=n.traits,ncol=n.traits)\n",
    "  \n",
    "  \n",
    "  #########  READ LD SCORES:\n",
    "  LOG(\"Reading in LD scores\")\n",
    " \n",
    "  if(select == FALSE){\n",
    "  x <- do.call(\"rbind\", lapply(1:chr, function(i) {\n",
    "    suppressMessages(read_delim(\n",
    "      file.path(ld, paste0(i, \".l2.ldscore.gz\")),\n",
    "      delim = \"\\t\", escape_double = FALSE, trim_ws = TRUE, progress = FALSE))\n",
    "  }))\n",
    "  }\n",
    "  \n",
    "  if(select == \"ODD\"){\n",
    "    x <- do.call(\"rbind\", lapply(odd, function(i) {\n",
    "      suppressMessages(read_delim(\n",
    "        file.path(ld, paste0(i, \".l2.ldscore.gz\")),\n",
    "        delim = \"\\t\", escape_double = FALSE, trim_ws = TRUE, progress = FALSE))\n",
    "    }))\n",
    "  }\n",
    "  \n",
    "  if(select == \"EVEN\"){\n",
    "    x <- do.call(\"rbind\", lapply(even, function(i) {\n",
    "      suppressMessages(read_delim(\n",
    "        file.path(ld, paste0(i, \".l2.ldscore.gz\")),\n",
    "        delim = \"\\t\", escape_double = FALSE, trim_ws = TRUE, progress = FALSE))\n",
    "    }))\n",
    "  }\n",
    "\n",
    "  if(is.numeric(select)){\n",
    "    x <- do.call(\"rbind\", lapply(select, function(i) {\n",
    "      suppressMessages(read_delim(\n",
    "        file.path(ld, paste0(i, \".l2.ldscore.gz\")),\n",
    "        delim = \"\\t\", escape_double = FALSE, trim_ws = TRUE, progress = FALSE))\n",
    "    }))\n",
    "  }\n",
    "  \n",
    "  \n",
    "  x$CM <- NULL\n",
    "  x$MAF <- NULL\n",
    "  \n",
    "  \n",
    "  ######### READ weights:\n",
    "  if(sep_weights){\n",
    "    if(select == FALSE){\n",
    "    w <- do.call(\"rbind\", lapply(1:chr, function(i) {\n",
    "      suppressMessages(read_delim(\n",
    "        file.path(wld, paste0(i, \".l2.ldscore.gz\")),\n",
    "        delim = \"\\t\", escape_double = FALSE, trim_ws = TRUE, progress = FALSE))\n",
    "    }))\n",
    "    }\n",
    "    if(select == \"EVEN\"){\n",
    "      w <- do.call(\"rbind\", lapply(even, function(i) {\n",
    "        suppressMessages(read_delim(\n",
    "          file.path(wld, paste0(i, \".l2.ldscore.gz\")),\n",
    "          delim = \"\\t\", escape_double = FALSE, trim_ws = TRUE, progress = FALSE))\n",
    "      }))\n",
    "    }\n",
    "    if(select == \"ODD\"){\n",
    "      w <- do.call(\"rbind\", lapply(even, function(i) {\n",
    "        suppressMessages(read_delim(\n",
    "          file.path(wld, paste0(i, \".l2.ldscore.gz\")),\n",
    "          delim = \"\\t\", escape_double = FALSE, trim_ws = TRUE, progress = FALSE))\n",
    "      }))\n",
    "    }\n",
    "      if(is.numeric(select)){\n",
    "        w <- do.call(\"rbind\", lapply(select, function(i) {\n",
    "          suppressMessages(read_delim(\n",
    "            file.path(wld, paste0(i, \".l2.ldscore.gz\")),\n",
    "            delim = \"\\t\", escape_double = FALSE, trim_ws = TRUE, progress = FALSE))\n",
    "        }))\n",
    "    }\n",
    "  }else{w<-x}\n",
    "  \n",
    "  w$CM <- NULL\n",
    "  w$MAF <- NULL\n",
    "  \n",
    "  colnames(w)[ncol(w)] <- \"wLD\"\n",
    "  \n",
    "  ### READ M\n",
    "  \n",
    "  if(select == FALSE){\n",
    "  m <- do.call(\"rbind\", lapply(1:chr, function(i) {\n",
    "    suppressMessages(read_csv(file.path(ld, paste0(i, \".l2.M_5_50\")), col_names = FALSE))\n",
    "  }))\n",
    "  }\n",
    "  \n",
    "  if(select == \"EVEN\"){\n",
    "    m <- do.call(\"rbind\", lapply(even, function(i) {\n",
    "      suppressMessages(read_csv(file.path(ld, paste0(i, \".l2.M_5_50\")), col_names = FALSE))\n",
    "    }))\n",
    "  }\n",
    "  \n",
    "  if(select == \"ODD\"){\n",
    "    m <- do.call(\"rbind\", lapply(odd, function(i) {\n",
    "      suppressMessages(read_csv(file.path(ld, paste0(i, \".l2.M_5_50\")), col_names = FALSE))\n",
    "    }))\n",
    "  }\n",
    "  \n",
    "  if(is.numeric(select)){\n",
    "    m <- do.call(\"rbind\", lapply(select, function(i) {\n",
    "      suppressMessages(read_csv(file.path(ld, paste0(i, \".l2.M_5_50\")), col_names = FALSE))\n",
    "    }))\n",
    "  }\n",
    "  \n",
    "  M.tot <- sum(m)\n",
    "  m <- M.tot\n",
    "  \n",
    "  ### READ ALL CHI2 + MERGE WITH LDSC FILES\n",
    "  s <- 0\n",
    "  \n",
    "  all_y <- lapply(traits, function(chi1) {\n",
    "    \n",
    "    ## READ chi2\n",
    "    y1 <- suppressMessages(na.omit(read_delim(\n",
    "      chi1, delim = \"\\t\", escape_double = FALSE, trim_ws = TRUE, progress = FALSE)))\n",
    "    \n",
    "    LOG(\"Read in summary statistics [\", s <<- s + 1, \"/\", n.traits, \"] from: \", chi1)\n",
    "    \n",
    "    ## Merge files\n",
    "    merged <- merge(y1[, c(\"SNP\", \"N\", \"Z\", \"A1\")], w[, c(\"SNP\", \"wLD\")], by = \"SNP\", sort = FALSE)\n",
    "    merged <- merge(merged, x, by = \"SNP\", sort = FALSE)\n",
    "    merged <- merged[with(merged, order(CHR, BP)), ]\n",
    "    \n",
    "    LOG(\"Out of \", nrow(y1), \" SNPs, \", nrow(merged), \" remain after merging with LD-score files\")\n",
    "    \n",
    "    ## REMOVE SNPS with excess chi-square:\n",
    "    \n",
    "    if(is.na(chisq.max)){\n",
    "    chisq.max <- max(0.001 * max(merged$N), 80)\n",
    "    }\n",
    "    rm <- (merged$Z^2 > chisq.max)\n",
    "    merged <- merged[!rm, ]\n",
    "    \n",
    "    LOG(\"Removing \", sum(rm), \" SNPs with Chi^2 > \", chisq.max, \"; \", nrow(merged), \" remain\")\n",
    "    \n",
    "    merged\n",
    "  })\n",
    "  \n",
    "  # count the total nummer of runs, both loops\n",
    "  s <- 1\n",
    "  \n",
    "  for(j in 1:n.traits){\n",
    "    \n",
    "    chi1 <- traits[j]\n",
    "    \n",
    "    y1 <- all_y[[j]]\n",
    "    y1$chi1 <- y1$Z^2\n",
    "    \n",
    "    for(k in j:length(traits)){\n",
    "      \n",
    "      ##### HERITABILITY code\n",
    "      \n",
    "      if(j == k){\n",
    "        \n",
    "        LOG(\"     \", \"     \", print = FALSE)\n",
    "        LOG(\"Estimating heritability [\", s, \"/\", n.V, \"] for: \", chi1)\n",
    "        \n",
    "        samp.prev <- sample.prev[j]\n",
    "        pop.prev <- population.prev[j]\n",
    "        \n",
    "        merged <- y1\n",
    "        n.snps <- nrow(merged)\n",
    "        \n",
    "        ## ADD INTERCEPT:\n",
    "        merged$intercept <- 1\n",
    "        merged$x.tot <- merged$L2\n",
    "        merged$x.tot.intercept <- 1\n",
    "        \n",
    "        \n",
    "        #### MAKE WEIGHTS:\n",
    "        \n",
    "        tot.agg <- (M.tot*(mean(merged$chi1)-1))/mean(merged$L2*merged$N)\n",
    "        tot.agg <- max(tot.agg,0)\n",
    "        tot.agg <- min(tot.agg,1)\n",
    "        merged$ld <- pmax(merged$L2, 1)\n",
    "        merged$w.ld <- pmax(merged$wLD, 1)\n",
    "        merged$c <- tot.agg*merged$N/M.tot\n",
    "        merged$het.w <- 1/(2*(1+(merged$c*merged$ld))^2)\n",
    "        merged$oc.w <- 1/merged$w.ld\n",
    "        merged$w <- merged$het.w*merged$oc.w\n",
    "        merged$initial.w <- sqrt(merged$w)\n",
    "        merged$weights <- merged$initial.w/sum(merged$initial.w)\n",
    "        \n",
    "        N.bar <- mean(merged$N)\n",
    "        \n",
    "        \n",
    "        ## preweight LD and chi:\n",
    "        \n",
    "        weighted.LD <- as.matrix(cbind(merged$L2,merged$intercept)*merged$weights)\n",
    "        weighted.chi <- as.matrix(merged$chi1*merged$weights)\n",
    "        \n",
    "        \n",
    "        ## Perfrom analysis:\n",
    "        \n",
    "        n.annot <- 1\n",
    "        \n",
    "        \n",
    "        select.from <- floor(seq(from=1,to=n.snps,length.out =(n.blocks+1)))\n",
    "        select.to <- c(select.from[2:n.blocks]-1,n.snps)\n",
    "        \n",
    "        xty.block.values <- matrix(data=NA,nrow=n.blocks,ncol =(n.annot+1))\n",
    "        xtx.block.values <- matrix(data=NA,nrow =((n.annot+1)* n.blocks),ncol =(n.annot+1))\n",
    "        colnames(xty.block.values)<- colnames(xtx.block.values)<- colnames(weighted.LD)\n",
    "        replace.from <- seq(from=1,to=nrow(xtx.block.values),by =(n.annot+1))\n",
    "        replace.to <- seq(from =(n.annot+1),to=nrow(xtx.block.values),by =(n.annot+1))\n",
    "        for(i in 1:n.blocks){\n",
    "          xty.block.values[i,] <- t(t(weighted.LD[select.from[i]:select.to[i],])%*% weighted.chi[select.from[i]:select.to[i],])\n",
    "          xtx.block.values[replace.from[i]:replace.to[i],] <- as.matrix(t(weighted.LD[select.from[i]:select.to[i],])%*% weighted.LD[select.from[i]:select.to[i],])\n",
    "        }\n",
    "        xty <- as.matrix(colSums(xty.block.values))\n",
    "        xtx <- matrix(data=NA,nrow =(n.annot+1),ncol =(n.annot+1))\n",
    "        colnames(xtx)<- colnames(weighted.LD)\n",
    "        for(i in 1:nrow(xtx)){xtx[i,] <- t(colSums(xtx.block.values[seq(from=i,to=nrow(xtx.block.values),by=ncol(weighted.LD)),]))}\n",
    "        \n",
    "        reg <- solve(xtx, xty)\n",
    "        intercept <- reg[2]\n",
    "        coefs <- reg[1]/N.bar\n",
    "        reg.tot <- coefs*m\n",
    "        \n",
    "        delete.from <- seq(from=1,to=nrow(xtx.block.values),by=ncol(xtx.block.values))\n",
    "        delete.to <- seq(from=ncol(xtx.block.values),to=nrow(xtx.block.values),by=ncol(xtx.block.values))\n",
    "        delete.values <- matrix(data=NA,nrow=n.blocks,ncol =(n.annot+1))\n",
    "        colnames(delete.values)<- colnames(weighted.LD)\n",
    "        for(i in 1:n.blocks){\n",
    "          xty.delete <- xty-xty.block.values[i,]\n",
    "          xtx.delete <- xtx-xtx.block.values[delete.from[i]:delete.to[i],]\n",
    "          delete.values[i,] <- solve(xtx.delete, xty.delete)\n",
    "        }\n",
    "        \n",
    "        tot.delete.values <- delete.values[,1:n.annot]\n",
    "        pseudo.values <- matrix(data=NA,nrow=n.blocks,ncol=length(reg))\n",
    "        colnames(pseudo.values)<- colnames(weighted.LD)\n",
    "        for(i in 1:n.blocks){pseudo.values[i,] <- (n.blocks*reg)-((n.blocks-1)* delete.values[i,])}\n",
    "        \n",
    "        jackknife.cov <- cov(pseudo.values)/n.blocks\n",
    "        jackknife.se <- sqrt(diag(jackknife.cov))\n",
    "        intercept.se <- jackknife.se[length(jackknife.se)]\n",
    "        coef.cov <- jackknife.cov[1:n.annot,1:n.annot]/(N.bar^2)\n",
    "        \n",
    "        cat.cov <- coef.cov*(m %*% t(m))\n",
    "        tot.cov <- sum(cat.cov)\n",
    "        tot.se <- sqrt(tot.cov)\n",
    "        \n",
    "        V.hold[,s] <- pseudo.values[,1]\n",
    "        N.vec[1,s] <- N.bar\n",
    "        \n",
    "        if(is.na(pop.prev)==F & is.na(samp.prev)==F){\n",
    "          conversion.factor <- (pop.prev^2*(1-pop.prev)^2)/(samp.prev*(1-samp.prev)* dnorm(qnorm(1-pop.prev))^2)\n",
    "          Liab.S[j] <- conversion.factor\n",
    "          LOG(\"     \", print = FALSE)\n",
    "          LOG(\"Please note that the results initially printed to the screen and log file reflect the NON-liability h2 and cov_g. However, a liability conversion is being used for trait \",\n",
    "              chi1, \" when creating the genetic covariance matrix used as input for Genomic SEM and liability scale results are printed at the end of the log file.\")\n",
    "          LOG(\"     \", print = FALSE)\n",
    "        }\n",
    "        \n",
    "        cov[j,j] <- reg.tot\n",
    "        I[j,j] <- intercept\n",
    "        \n",
    "        lambda.gc <- median(merged$chi1) / qchisq(0.5, df = 1)\n",
    "        mean.Chi <- mean(merged$chi1)\n",
    "        ratio <- (intercept - 1) / (mean.Chi - 1)\n",
    "        ratio.se <- intercept.se / (mean.Chi - 1)\n",
    "        \n",
    "        LOG(\"Heritability Results for trait: \", chi1)\n",
    "        LOG(\"Mean Chi^2 across remaining SNPs: \", round(mean.Chi, 4))\n",
    "        LOG(\"Lambda GC: \", round(lambda.gc, 4))\n",
    "        LOG(\"Intercept: \", round(intercept, 4), \" (\", round(intercept.se, 4), \")\")\n",
    "        LOG(\"Ratio: \", round(ratio, 4), \" (\", round(ratio.se, 4), \")\")\n",
    "        LOG(\"Total Observed Scale h2: \", round(reg.tot, 4), \" (\", round(tot.se, 4), \")\")\n",
    "        LOG(\"h2 Z: \", format(reg.tot / tot.se), digits = 3)\n",
    "      }\n",
    "      \n",
    "      \n",
    "      ##### GENETIC COVARIANCE code\n",
    "      \n",
    "      if(j != k){\n",
    "        \n",
    "        LOG(\"     \", print = FALSE)\n",
    "        \n",
    "        chi2 <- traits[k]\n",
    "        LOG(\"Calculating genetic covariance [\", s, \"/\", n.V, \"] for traits: \", chi1, \" and \", chi2)\n",
    "        \n",
    "        # Reuse the data read in for heritability\n",
    "        y2 <- all_y[[k]]\n",
    "        y <- merge(y1, y2[, c(\"SNP\", \"N\", \"Z\", \"A1\")], by = \"SNP\", sort = FALSE)\n",
    "        \n",
    "        y$Z.x <- ifelse(y$A1.y == y$A1.x, y$Z.x, -y$Z.x)\n",
    "        y$ZZ <- y$Z.y * y$Z.x\n",
    "        y$chi2 <- y$Z.y^2\n",
    "        merged <- na.omit(y)\n",
    "        n.snps <- nrow(merged)\n",
    "        \n",
    "        LOG(n.snps, \" SNPs remain after merging \", chi1, \" and \", chi2, \" summary statistics\")\n",
    "        \n",
    "        ## ADD INTERCEPT:\n",
    "        merged$intercept <- 1\n",
    "        merged$x.tot <- merged$L2\n",
    "        merged$x.tot.intercept <- 1\n",
    "        \n",
    "        \n",
    "        #### MAKE WEIGHTS:\n",
    "        \n",
    "        tot.agg <- (M.tot*(mean(merged$chi1)-1))/mean(merged$L2*merged$N.x)\n",
    "        tot.agg <- max(tot.agg,0)\n",
    "        tot.agg <- min(tot.agg,1)\n",
    "        merged$ld <- pmax(merged$L2, 1)\n",
    "        merged$w.ld <- pmax(merged$wLD, 1)\n",
    "        merged$c <- tot.agg*merged$N.x/M.tot\n",
    "        merged$het.w <- 1/(2*(1+(merged$c*merged$ld))^2)\n",
    "        merged$oc.w <- 1/merged$w.ld\n",
    "        merged$w <- merged$het.w*merged$oc.w\n",
    "        merged$initial.w <- sqrt(merged$w)\n",
    "        \n",
    "        tot.agg2 <- (M.tot*(mean(merged$chi2)-1))/mean(merged$L2*merged$N.y)\n",
    "        tot.agg2 <- max(tot.agg2,0)\n",
    "        tot.agg2 <- min(tot.agg2,1)\n",
    "        merged$ld2 <- pmax(merged$L2, 1)\n",
    "        merged$w.ld2 <- pmax(merged$wLD, 1)\n",
    "        merged$c2 <- tot.agg2*merged$N.y/M.tot\n",
    "        merged$het.w2 <- 1/(2*(1+(merged$c2*merged$ld))^2)\n",
    "        merged$oc.w2 <- 1/merged$w.ld2\n",
    "        merged$w2 <- merged$het.w2*merged$oc.w2\n",
    "        merged$initial.w2 <- sqrt(merged$w2)\n",
    "        \n",
    "        \n",
    "        merged$weights_cov <- (merged$initial.w + merged$initial.w2)/sum(merged$initial.w + merged$initial.w2 )\n",
    "        \n",
    "        N.bar <- sqrt(mean(merged$N.x)*mean(merged$N.y))\n",
    "        \n",
    "        ## preweight LD and chi:\n",
    "        \n",
    "        weighted.LD <- as.matrix(cbind(merged$L2,merged$intercept)*merged$weights)\n",
    "        weighted.chi <- as.matrix(merged$ZZ *merged$weights_cov)\n",
    "        \n",
    "        ## Perfrom analysis:\n",
    "        \n",
    "        \n",
    "        n.annot <- 1\n",
    "        \n",
    "        \n",
    "        select.from <- floor(seq(from=1,to=n.snps,length.out =(n.blocks+1)))\n",
    "        select.to <- c(select.from[2:n.blocks]-1,n.snps)\n",
    "        \n",
    "        xty.block.values <- matrix(data=NA,nrow=n.blocks,ncol =(n.annot+1))\n",
    "        xtx.block.values <- matrix(data=NA,nrow =((n.annot+1)* n.blocks),ncol =(n.annot+1))\n",
    "        colnames(xty.block.values)<- colnames(xtx.block.values)<- colnames(weighted.LD)\n",
    "        replace.from <- seq(from=1,to=nrow(xtx.block.values),by =(n.annot+1))\n",
    "        replace.to <- seq(from =(n.annot+1),to=nrow(xtx.block.values),by =(n.annot+1))\n",
    "        for(i in 1:n.blocks){\n",
    "          xty.block.values[i,] <- t(t(weighted.LD[select.from[i]:select.to[i],])%*% weighted.chi[select.from[i]:select.to[i],])\n",
    "          xtx.block.values[replace.from[i]:replace.to[i],] <- as.matrix(t(weighted.LD[select.from[i]:select.to[i],])%*% weighted.LD[select.from[i]:select.to[i],])\n",
    "        }\n",
    "        xty <- as.matrix(colSums(xty.block.values))\n",
    "        xtx <- matrix(data=NA,nrow =(n.annot+1),ncol =(n.annot+1))\n",
    "        colnames(xtx)<- colnames(weighted.LD)\n",
    "        for(i in 1:nrow(xtx)){xtx[i,] <- t(colSums(xtx.block.values[seq(from=i,to=nrow(xtx.block.values),by=ncol(weighted.LD)),]))}\n",
    "        \n",
    "        reg <- solve(xtx, xty)\n",
    "        intercept <- reg[2]\n",
    "        coefs <- reg[1]/N.bar\n",
    "        reg.tot <- coefs*m\n",
    "        \n",
    "        delete.from <- seq(from=1,to=nrow(xtx.block.values),by=ncol(xtx.block.values))\n",
    "        delete.to <- seq(from=ncol(xtx.block.values),to=nrow(xtx.block.values),by=ncol(xtx.block.values))\n",
    "        delete.values <- matrix(data=NA,nrow=n.blocks,ncol =(n.annot+1))\n",
    "        colnames(delete.values)<- colnames(weighted.LD)\n",
    "        for(i in 1:n.blocks){\n",
    "          xty.delete <- xty-xty.block.values[i,]\n",
    "          xtx.delete <- xtx-xtx.block.values[delete.from[i]:delete.to[i],]\n",
    "          delete.values[i,] <- solve(xtx.delete, xty.delete)\n",
    "        }\n",
    "        \n",
    "        tot.delete.values <- delete.values[,1:n.annot]\n",
    "        pseudo.values <- matrix(data=NA,nrow=n.blocks,ncol=length(reg))\n",
    "        colnames(pseudo.values)<- colnames(weighted.LD)\n",
    "        for(i in 1:n.blocks){pseudo.values[i,] <- (n.blocks*reg)-((n.blocks-1)* delete.values[i,])}\n",
    "        \n",
    "        jackknife.cov <- cov(pseudo.values)/n.blocks\n",
    "        jackknife.se <- sqrt(diag(jackknife.cov))\n",
    "        intercept.se <- jackknife.se[length(jackknife.se)]\n",
    "        coef.cov <- jackknife.cov[1:n.annot,1:n.annot]/(N.bar^2)\n",
    "        cat.cov <- coef.cov*(m %*% t(m))\n",
    "        tot.cov <- sum(cat.cov)\n",
    "        tot.se <- sqrt(tot.cov)\n",
    "        \n",
    "        V.hold[, s] <- pseudo.values[, 1]\n",
    "        N.vec[1, s] <- N.bar\n",
    "        \n",
    "        cov[k, j] <- cov[j, k] <- reg.tot\n",
    "        I[k, j] <- I[j, k] <- intercept\n",
    "        \n",
    "        LOG(\"Results for genetic covariance between: \", chi1, \" and \", chi2)\n",
    "        LOG(\"Mean Z*Z: \", round(mean(merged$ZZ), 4))\n",
    "        LOG(\"Cross trait Intercept: \", round(intercept, 4), \" (\", round(intercept.se, 4), \")\")\n",
    "        LOG(\"Total Observed Scale Genetic Covariance (g_cov): \", round(reg.tot, 4), \" (\", round(tot.se, 4), \")\")\n",
    "        LOG(\"g_cov Z: \", format(reg.tot / tot.se), digits = 3)\n",
    "        LOG(\"g_cov P-value: \", format(2 * pnorm(abs(reg.tot / tot.se), lower.tail = FALSE), digits = 5))\n",
    "      }\n",
    "      \n",
    "      ### Total count\n",
    "      s <- s + 1\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  \n",
    "  ## Scale V to N per study (assume m constant)\n",
    "  # /!\\ crossprod instead of tcrossprod because N.vec is a one-row matrix\n",
    "  v.out <- cov(V.hold) / crossprod(N.vec * (sqrt(n.blocks) / m))\n",
    "  \n",
    "  ### Scale S and V to liability:\n",
    "  ratio <- tcrossprod(sqrt(Liab.S))\n",
    "  S <- cov * ratio\n",
    "  \n",
    "  #calculate the ratio of the rescaled and original S matrices\n",
    "  scaleO <- gdata::lowerTriangle(ratio, diag = TRUE)\n",
    "  \n",
    "  #rescale the sampling correlation matrix by the appropriate diagonals\n",
    "  V <- v.out * tcrossprod(scaleO)\n",
    "  \n",
    "  \n",
    "  #name traits according to trait.names argument\n",
    "  #use general format of V1-VX if no names provided\n",
    "  colnames(S) <- if (is.null(trait.names)) paste0(\"V\", 1:ncol(S)) else trait.names\n",
    "  \n",
    "  if(mean(Liab.S)!=1){\n",
    "    r<-nrow(S)\n",
    "    SE<-matrix(0, r, r)\n",
    "    SE[lower.tri(SE,diag=TRUE)] <-sqrt(diag(V))\n",
    "    \n",
    "    LOG(c(\"     \", \"     \"), print = FALSE)\n",
    "    LOG(\"Liability Scale Results\")\n",
    "    \n",
    "    for(j in 1:n.traits){\n",
    "      if(is.null(trait.names)){\n",
    "        chi1<-traits[j]\n",
    "      }else{chi1 <- trait.names[j]}\n",
    "      for(k in j:length(traits)){\n",
    "        if(j == k){\n",
    "          LOG(\"     \", print = FALSE)\n",
    "          LOG(\"Liability scale results for: \", chi1)\n",
    "          LOG(\"Total Liability Scale h2: \", round(S[j, j], 4), \" (\", round(SE[j, j], 4), \")\")\n",
    "        }\n",
    "        \n",
    "        if(j != k){\n",
    "          if(is.null(trait.names)){\n",
    "            chi2<-traits[k]\n",
    "          }else{chi2 <- trait.names[k]}\n",
    "          LOG(\"Total Liability Scale Genetic Covariance between \", chi1, \" and \",\n",
    "              chi2, \": \", round(S[k, j], 4), \" (\", round(SE[k, j], 4), \")\")\n",
    "          LOG(\"     \", print = FALSE)\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  \n",
    "  if(all(diag(S) > 0)){\n",
    "    \n",
    "    ##calculate standardized results to print genetic correlations to log and screen\n",
    "    ratio <- tcrossprod(1 / sqrt(diag(S)))\n",
    "    S_Stand <- S * ratio\n",
    "    \n",
    "    #calculate the ratio of the rescaled and original S matrices\n",
    "    scaleO <- gdata::lowerTriangle(ratio, diag = TRUE)\n",
    "    \n",
    "    ## MAke sure that if ratio in NaN (devision by zero) we put the zero back in\n",
    "    # -> not possible because of 'all(diag(S) > 0)'\n",
    "    # scaleO[is.nan(scaleO)] <- 0\n",
    "    \n",
    "    #rescale the sampling correlation matrix by the appropriate diagonals\n",
    "    V_Stand <- V * tcrossprod(scaleO)\n",
    "    \n",
    "    #enter SEs from diagonal of standardized V\n",
    "    r<-nrow(S)\n",
    "    SE_Stand<-matrix(0, r, r)\n",
    "    SE_Stand[lower.tri(SE_Stand,diag=TRUE)] <-sqrt(diag(V_Stand))\n",
    "    \n",
    "    \n",
    "    LOG(c(\"     \", \"     \"), print = FALSE)\n",
    "    LOG(\"Genetic Correlation Results\")\n",
    "    \n",
    "    for(j in 1:n.traits){\n",
    "      if(is.null(trait.names)){\n",
    "        chi1<-traits[j]\n",
    "      }else{chi1 <- trait.names[j]}\n",
    "      for(k in j:length(traits)){\n",
    "        if(j != k){\n",
    "          if(is.null(trait.names)){\n",
    "            chi2<-traits[k]\n",
    "          }else{chi2 <- trait.names[k]}\n",
    "          LOG(\"Genetic Correlation between \", chi1, \" and \", chi2, \": \",\n",
    "              round(S_Stand[k, j], 4), \" (\", round(SE_Stand[k, j], 4), \")\")\n",
    "          LOG(\"     \", print = FALSE)\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }else{\n",
    "    warning(\"Your genetic covariance matrix includes traits estimated to have a negative heritability.\")\n",
    "    LOG(\"Your genetic covariance matrix includes traits estimated to have a negative heritability.\", print = FALSE)\n",
    "    LOG(\"Genetic correlation results could not be computed due to negative heritability estimates.\")\n",
    "  }\n",
    "  \n",
    "  end.time <- Sys.time()\n",
    "  \n",
    "  total.time <- difftime(time1=end.time,time2=begin.time,units=\"sec\")\n",
    "  mins <- floor(floor(total.time)/60)\n",
    "  secs <- floor(total.time-mins*60)\n",
    "  \n",
    "  LOG(\"     \", print = FALSE)\n",
    "  LOG(\"LDSC finished running at \", end.time)\n",
    "  LOG(\"Running LDSC for all files took \", mins, \" minutes and \", secs, \" seconds\")\n",
    "  LOG(\"     \", print = FALSE)\n",
    "  \n",
    "  flush(log.file)\n",
    "  close(log.file)\n",
    "  \n",
    "  if(stand){\n",
    "    list(V=V,S=S,I=I,N=N.vec,m=m,V_Stand=V_Stand,S_Stand=S_Stand)\n",
    "  } else {\n",
    "    list(V=V,S=S,I=I,N=N.vec,m=m)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "better-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "traits <- c(\"mdd.sumstats\",\"bipolar.sumstats\")\n",
    "sample.prev <- c(.39,.45)\n",
    "population.prev <- c(.01,.01)\n",
    "ld <- \"eur_w_ld_chr/\"\n",
    "wld <- \"eur_w_ld_chr/\"\n",
    "trait.names<-c(\"MDD\",\"BIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "minimal-mexico",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Multivariate ld-score regression of 2 traits (mdd.sumstats bipolar.sumstats) began at: 2021-04-11 12:55:27\"\n",
      "[1] \"Reading in LD scores\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in date_names_lang(date_names):\n",
      "“restarting interrupted promise evaluation”"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in date_names_lang(date_names): cannot open file '/Users/rachel/opt/anaconda3/envs/stat/lib/R/library/readr/R/sysdata.rdb': No such file or directory\n",
     "output_type": "error",
     "traceback": [
      "Error in date_names_lang(date_names): cannot open file '/Users/rachel/opt/anaconda3/envs/stat/lib/R/library/readr/R/sysdata.rdb': No such file or directory\nTraceback:\n",
      "1. ldsc(traits, sample.prev, population.prev, ld, wld, trait.names)",
      "2. do.call(\"rbind\", lapply(1:chr, function(i) {\n .     suppressMessages(read_delim(file.path(ld, paste0(i, \".l2.ldscore.gz\")), \n .         delim = \"\\t\", escape_double = FALSE, trim_ws = TRUE, \n .         progress = FALSE))\n . }))   # at line 59-63 of file <text>",
      "3. lapply(1:chr, function(i) {\n .     suppressMessages(read_delim(file.path(ld, paste0(i, \".l2.ldscore.gz\")), \n .         delim = \"\\t\", escape_double = FALSE, trim_ws = TRUE, \n .         progress = FALSE))\n . })   # at line 59-63 of file <text>",
      "4. FUN(X[[i]], ...)",
      "5. suppressMessages(read_delim(file.path(ld, paste0(i, \".l2.ldscore.gz\")), \n .     delim = \"\\t\", escape_double = FALSE, trim_ws = TRUE, progress = FALSE))   # at line 60-62 of file <text>",
      "6. withCallingHandlers(expr, message = function(c) invokeRestart(\"muffleMessage\"))",
      "7. read_delim(file.path(ld, paste0(i, \".l2.ldscore.gz\")), delim = \"\\t\", \n .     escape_double = FALSE, trim_ws = TRUE, progress = FALSE)   # at line 60-62 of file <text>",
      "8. read_delimited(file, tokenizer, col_names = col_names, col_types = col_types, \n .     locale = locale, skip = skip, skip_empty_rows = skip_empty_rows, \n .     comment = comment, n_max = n_max, guess_max = guess_max, \n .     progress = progress)",
      "9. col_spec_standardise(data, skip = skip, skip_empty_rows = skip_empty_rows, \n .     comment = comment, guess_max = guess_max, col_names = col_names, \n .     col_types = col_types, tokenizer = tokenizer, locale = locale)",
      "10. guess_header(ds_header, tokenizer, locale)",
      "11. guess_header_(datasource, tokenizer, locale)",
      "12. default_locale()",
      "13. locale()",
      "14. date_names_lang(date_names)"
     ]
    }
   ],
   "source": [
    "LDSCoutput <- ldsc(traits, sample.prev, population.prev, ld, wld, trait.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "absolute-tissue",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'LDSCoutput' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'LDSCoutput' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "LDSCoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-independence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
